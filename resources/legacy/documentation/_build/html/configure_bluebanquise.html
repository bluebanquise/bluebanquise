

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>6. [Core] - Configure BlueBanquise &mdash; BlueBanquise Documentation 1.5.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="7. [Core] - Deploy BlueBanquise" href="deploy_bluebanquise.html" />
    <link rel="prev" title="5. [Core] - Bootstrap base system" href="bootstrap.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> BlueBanquise Documentation
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="vocabulary.html">2. Vocabulary</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_sysadmin.html">3. [Training] - Cluster SysAdmin</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_ansible.html">4. [Training] - Ansible</a></li>
<li class="toctree-l1"><a class="reference internal" href="bootstrap.html">5. [Core] - Bootstrap base system</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">6. [Core] - Configure BlueBanquise</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#enable-bluebanquise-and-ssh">6.1. Enable BlueBanquise and ssh</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configure-inventory">6.2. Configure inventory</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#check-example-inventory">6.2.1. Check example inventory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#review-groups">6.2.2. Review groups</a></li>
<li class="toctree-l3"><a class="reference internal" href="#review-nodes">6.2.3. Review nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#management-node">6.2.3.1. Management node</a></li>
<li class="toctree-l4"><a class="reference internal" href="#other-nodes">6.2.3.2. Other nodes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#review-logical-networks">6.2.4. Review logical networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#review-general-configuration">6.2.5. Review general configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#externals">6.2.5.1. Externals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#network">6.2.5.2. Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#repositories">6.2.5.3. Repositories</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nfs">6.2.5.4. NFS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#general">6.2.5.5. General</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#review-equipment-default-parameters">6.2.6. Review equipment default parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#equipment-profile-variables">6.2.6.1. Equipment profile variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#authentication">6.2.6.2. Authentication</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deploy_bluebanquise.html">7. [Core] - Deploy BlueBanquise</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiple_icebergs.html">8. [Core] - Manage multiple icebergs</a></li>
<li class="toctree-l1"><a class="reference internal" href="diskless.html">9. [Core] - Diskless</a></li>
<li class="toctree-l1"><a class="reference internal" href="high_availability.html">10. [Community] - High Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitoring.html">11. [Community] - Monitoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="containers.html">12. Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="stories.html">13. Stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="roles.html">14. Roles list</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">15. References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BlueBanquise Documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><span class="section-number">6. </span>[Core] - Configure BlueBanquise</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/configure_bluebanquise.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="core-configure-bluebanquise">
<h1><span class="section-number">6. </span>[Core] - Configure BlueBanquise<a class="headerlink" href="#core-configure-bluebanquise" title="Permalink to this headline">¶</a></h1>
<p>At this point, you should have an operating system with Ansible installed on it,
and basic OS repositories. You also have installed BlueBanquise package and its
dependencies, and your main NIC (Network Interface Controller) is configured and
activated (up).</p>
<img alt="_images/documentation_example_single_island_step_1.svg" class="align-center" src="_images/documentation_example_single_island_step_1.svg" /><div class="section" id="enable-bluebanquise-and-ssh">
<h2><span class="section-number">6.1. </span>Enable BlueBanquise and ssh<a class="headerlink" href="#enable-bluebanquise-and-ssh" title="Permalink to this headline">¶</a></h2>
<p>By default, Ansible will check presence of configuration file at multiple
locations:</p>
<ol class="arabic simple">
<li><p>Environment variable <strong>ANSIBLE_CONFIG</strong></p></li>
<li><p>ansible.cfg in the current working directory</p></li>
<li><p>.ansible.cfg in the home directory</p></li>
<li><p>/etc/ansible/ansible.cfg</p></li>
</ol>
<p>The first found is used as main configuration.</p>
<p>To enable BlueBanquise, we need Ansible to use /etc/bluebanquise/ansible.cfg.
To do so, set ANSIBLE_CONFIG:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">ANSIBLE_CONFIG</span><span class="o">=</span>/etc/bluebanquise/ansible.cfg
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can revert to Ansible default behavior by unsetting this variable. It
allows to use both default Ansible and BlueBanquise together.</p>
</div>
<p>Edit /etc/hosts file, and add “management1” (or whatever your current
management node hostname) with its target ip (the one set on the main NIC):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.10.0.1   management1
</pre></div>
</div>
<p>This will allow us to bootstrap the management configuration.</p>
<p>Generate now an ssh key for current management1 host, and do not set a
passphrase (leave empty when asked and press enter):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ssh-keygen -t ed25519
</pre></div>
</div>
<p>Then spread this key on the current host so that management1 can ssh on itself
passwordless (you will be asked current root password to establish this first
ssh connection):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ssh-copy-id management1
</pre></div>
</div>
<p>Now, ensure you can ssh without password now:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ssh management1
</pre></div>
</div>
<p>It is time to configure the inventory to match cluster needs.</p>
</div>
<div class="section" id="configure-inventory">
<h2><span class="section-number">6.2. </span>Configure inventory<a class="headerlink" href="#configure-inventory" title="Permalink to this headline">¶</a></h2>
<div class="section" id="check-example-inventory">
<h3><span class="section-number">6.2.1. </span>Check example inventory<a class="headerlink" href="#check-example-inventory" title="Permalink to this headline">¶</a></h3>
<p>An inventory example is provided in
/etc/bluebanquise/resources/examples/simple_cluster/ and will be used
as a base for this documentation.</p>
<p>This example match the cluster exposed previously.</p>
<p>Copy it to use it as your new inventory starting point:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cp -a /etc/bluebanquise/resources/examples/simple_cluster/inventory /etc/bluebanquise/inventory
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Ansible will read <strong>ALL</strong> files in the inventory. <strong>NEVER do a backup of a file
here!</strong>
Backup in another location, outside of /etc/bluebanquise/inventory.</p>
</div>
</div>
<div class="section" id="review-groups">
<h3><span class="section-number">6.2.2. </span>Review groups<a class="headerlink" href="#review-groups" title="Permalink to this headline">¶</a></h3>
<p>In BlueBanquise, there are 3 main types of groups, apart of user’s custom groups.</p>
<p>Use command ansible-inventory to display current groups in the inventory:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[root@management1 ~]# ansible-inventory --graph
@all:
  |--@internal:
  |  |--dummy
  |--@mg_computes:
  |  |--@equipment_typeC:
  |  |  |--compute1
  |  |  |--compute2
  |  |  |--compute3
  |  |  |--compute4
  |--@mg_logins:
  |  |--@equipment_typeL:
  |  |  |--login1
  |--@mg_managements:
  |  |--@equipment_typeM:
  |  |  |--management1
  |--@mg_storages:
  |  |--@equipment_typeS:
  |  |  |--storage1
  |--@rack_1:
  |  |--compute1
  |  |--compute2
  |  |--compute3
  |  |--compute4
  |  |--login1
  |  |--management1
  |  |--storage1
  |--@ungrouped:
[root@management1 ~]#
</pre></div>
</div>
<p>In this example inventory, you can see <strong>mg_</strong> groups, and <strong>equipment_</strong> groups.
<em>rack_1</em> group is a user’s custom group and is not important for the stack to
operate properly.</p>
<p><strong>mg_</strong> groups are called master groups (or main groups), and define global
purpose of their nodes: storages, managements, logins, computes, etc.</p>
<p><strong>equipment_</strong> groups are called equipment profile groups, and define equipment
related settings of their nodes. These groups are linked to the hardware of
nodes. For example, if in <strong>mg_computes</strong> group, your cluster contains 2 type of
nodes, for example model_A and model_B servers, then you need to create 2
equipment profile groups, called equipment_model_A and equipment_model_B, that
contain their related nodes.</p>
<p>Equipment profiles are subgroups of master groups.</p>
</div>
<div class="section" id="review-nodes">
<h3><span class="section-number">6.2.3. </span>Review nodes<a class="headerlink" href="#review-nodes" title="Permalink to this headline">¶</a></h3>
<p>First step is to review the provided example configuration, and adapt it to your
configuration. The following part assume all path are relative to
/etc/bluebanquise/inventory/ folder.</p>
<div class="section" id="management-node">
<h4><span class="section-number">6.2.3.1. </span>Management node<a class="headerlink" href="#management-node" title="Permalink to this headline">¶</a></h4>
<p>Open file cluster/nodes/managements.yml, and visualize content:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">mg_managements</span><span class="p">:</span>
  <span class="nt">children</span><span class="p">:</span>
    <span class="nt">equipment_typeM</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">management1</span><span class="p">:</span>
          <span class="nt">bmc</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bmanagement1</span>
            <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.100.1</span>
            <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:dc:f8:f6</span>
            <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
          <span class="nt">network_interfaces</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">interface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">enp0s3</span>
              <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>
              <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:dc:f8:f5</span>
              <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
            <span class="p p-Indicator">-</span> <span class="nt">interface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ib0</span>
              <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.20.0.1</span>
              <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interconnect-1</span>
</pre></div>
</div>
<p>This file contains our management node configuration. Let’s review it, to
understand it.</p>
<p>First, the groups:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">mg_managements</span><span class="p">:</span>         <span class="c1"># This is the master group (also called main group), it is very useful with advanced configuration</span>
  <span class="nt">children</span><span class="p">:</span>             <span class="c1"># This is an Ansible instruction, indicating the below group is included in mg_managements group</span>
    <span class="nt">equipment_typeM</span><span class="p">:</span>    <span class="c1"># This is the equipment group of the management node. It always starts by &#39;equipment_&#39;</span>
      <span class="nt">hosts</span><span class="p">:</span>            <span class="c1"># This is an Ansible instruction, to list below the hosts member of this group</span>
        <span class="nt">management1</span><span class="p">:</span>    <span class="c1"># This is the hostname</span>
</pre></div>
</div>
<p>Now the BMC (if exist):</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">mg_managements</span><span class="p">:</span>
  <span class="nt">children</span><span class="p">:</span>
    <span class="nt">equipment_typeM</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">management1</span><span class="p">:</span>
          <span class="nt">bmc</span><span class="p">:</span>                      <span class="c1"># This instruction defines an attached BMC</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bmanagement1</span>      <span class="c1"># This is the hostname of the BMC</span>
            <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.100.1</span>        <span class="c1"># This is the ipv4 of the BMC</span>
            <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:dc:f8:f6</span>  <span class="c1"># This is the MAC hardware address of the BMC (for DHCP)</span>
            <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>         <span class="c1"># This is the logical network this interface is connected to. Logical networks will be seen later.</span>
</pre></div>
</div>
<p>Then the network interfaces and their associated networks:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">mg_managements</span><span class="p">:</span>
  <span class="nt">children</span><span class="p">:</span>
    <span class="nt">equipment_typeM</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">management1</span><span class="p">:</span>
          <span class="nt">bmc</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bmanagement1</span>
            <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.100.1</span>
            <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:dc:f8:f6</span>
            <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
          <span class="nt">network_interfaces</span><span class="p">:</span>         <span class="c1"># This is an instruction, to define bellow all host&#39;s NIC (Network Interface Controllers)</span>
            <span class="p p-Indicator">-</span> <span class="nt">interface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">enp0s3</span>       <span class="c1"># This is the NIC name (&#39;ip a&#39; command to get NIC list)</span>
              <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>          <span class="c1"># This is the expected ipv4 for this NIC</span>
              <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:dc:f8:f5</span>  <span class="c1"># This is the NIC MAC address, for the DHCP</span>
              <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>         <span class="c1"># This is the logical network this NIC is linked to</span>
            <span class="p p-Indicator">-</span> <span class="nt">interface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ib0</span>          <span class="c1"># This is another NIC, not in the dhcp so no MAC is provided</span>
              <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.20.0.1</span>
              <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interconnect-1</span>
</pre></div>
</div>
<p>It should not be too difficult to understand this file.</p>
<p>What is essential here is to understand that order network interfaces are
defined under <em>network_interfaces</em> variable matters. Rules are the following:</p>
<ul class="simple">
<li><p>The first interface in the list is the resolution interface. This is the one a ping will try to reach.</p></li>
<li><p>The first management network attached interface (management networks are explain in the next chapter) is the main network interface. This is the one ssh and so Ansible will use to connect to the node.</p></li>
</ul>
<p>If these rules do not comply with your needs, remember that the stack logic can
be precedenced: simply define new <em>j2_node_main_resolution_network</em>,
<em>j2_node_main_network</em>, etc variables (these variables are stored into <em>internal</em>
folder)</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>More network features and configurations are available, see the nic_nmcli role
readme file for more information.</p>
</div>
</div>
<div class="section" id="other-nodes">
<h4><span class="section-number">6.2.3.2. </span>Other nodes<a class="headerlink" href="#other-nodes" title="Permalink to this headline">¶</a></h4>
<p>Now, review computes, logins and storages nodes in their respective
<em>cluster/nodes/computes.yml</em>, <em>cluster/nodes/logins.yml</em> and
<em>cluster/nodes/storages.yml</em> files. Same rules apply.
You can also add more nodes, or if you have for example multiple type
of equipment for computes nodes, add other equipment groups
this way:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">mg_computes</span><span class="p">:</span>
  <span class="nt">children</span><span class="p">:</span>
    <span class="nt">equipment_typeC</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">compute1</span><span class="p">:</span>
        <span class="p p-Indicator">[</span><span class="nv">...</span><span class="p p-Indicator">]</span>
    <span class="nt">equipment_typeD</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">compute5</span><span class="p">:</span>
        <span class="p p-Indicator">[</span><span class="nv">...</span><span class="p p-Indicator">]</span>
    <span class="nt">equipment_typeE</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">compute10</span><span class="p">:</span>
        <span class="p p-Indicator">[</span><span class="nv">...</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Now, let’s have a look at the logical networks.</p>
</div>
</div>
<div class="section" id="review-logical-networks">
<h3><span class="section-number">6.2.4. </span>Review logical networks<a class="headerlink" href="#review-logical-networks" title="Permalink to this headline">¶</a></h3>
<p>In <strong>BlueBanquise</strong>, nodes are connected together through logical networks. Most
of the time, logical networks will match your physical network, but for advanced
networking, it can be different.</p>
<p>All networks are defined in <em>group_vars/all/general_settings/network.yml</em> file.
In this current example inventory, there are two networks provided:
<em>ice1-1</em> and <em>interconnect-1</em>.</p>
<p>Before reviewing the file, please read this <strong>IMPORTANT</strong> information: in
<strong>BlueBanquise</strong> there are two kind of networks: <strong>administration/management
networks</strong>, and the “others”.</p>
<p>An <strong>administration network</strong> is used to deploy and manage the nodes. It will be for
example used to run a DHCP server, handle the PXE stack, etc, and also all the
Ansible ssh connections. Administration networks have a strict naming
convention, which by default is: <strong>iceX-Y</strong> with X the iceberg number, and Y the
subnet number in this iceberg X. In our case, we are working on iceberg1
(default when disabling icebergs mechanism), and we only have one subnet, so our
administration network will be ice1-1. If we would need another subnet, its name
would have been ice1-2, etc.</p>
<p>Interconnect-1 is not an administration network as it is not using <strong>iceX-Y</strong>
pattern. So it belongs to the “others” networks.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In new versions of the stack, it is now possible to replace the number Y by a
string compatible with [0-9][a-z][A-Z] regex. For example ice1-prod.</p>
</div>
<p>Open file <em>group_vars/all/general_settings/network.yml</em> and let’s check part of
its content:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">networks</span><span class="p">:</span>                                             <span class="c1"># This defines the list of networks</span>
  <span class="nt">ice1-1</span><span class="p">:</span>                                             <span class="c1"># Network name</span>
    <span class="nt">subnet</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.0</span>                                 <span class="c1"># Network subnet</span>
    <span class="nt">prefix</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">16</span>                                        <span class="c1"># Network prefix</span>
    <span class="nt">netmask</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">255.255.0.0</span>                              <span class="c1"># Network netmask, must comply with prefix</span>
    <span class="nt">broadcast</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.255.255</span>                          <span class="c1"># Broadcast, deduced from subnet and prefix/netmask</span>
    <span class="nt">dhcp_unknown_range</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.254.1 10.10.254.254</span>     <span class="c1"># Optional, this is the range of ip where unknown nodes (i.e. not in the inventory) will be placed if asking for an ip</span>
    <span class="nt">gateway</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>                                <span class="c1"># Optional, define a gateway</span>
    <span class="nt">is_in_dhcp</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>                                  <span class="c1"># If you want this network to be in the dhcp (only apply to management networks)</span>
    <span class="nt">is_in_dns</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>                                   <span class="c1"># If you want this network to be in the dns</span>
    <span class="nt">services_ip</span><span class="p">:</span>                                      <span class="c1"># IPs or virtual IPs to bind to for each service. In our case, all services will be running on management1 so 10.10.0.1 for all</span>
      <span class="nt">pxe_ip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>
      <span class="nt">dns_ip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>
      <span class="nt">repository_ip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>
      <span class="nt">time_ip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>
      <span class="nt">log_ip</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.1</span>
</pre></div>
</div>
<p>All explanations are given above.</p>
<p>One note about <em>services_ip</em>: it is used if services are spread over multiple
managements, or in case of High Availability with virtual IPs. Ansible is not
able to gather this information alone from playbooks (it could, but this would
end up with a way too much complex stack), and so we have to provide it manually.
You can also set here an IP address from another subnet if your system has
network routing.</p>
<p>Now check content of the second network, interconnect-1 in file
<em>group_vars/all/general_settings/network.yml</em> . As this is <strong>not</strong> an
administration network, its configuration is easy.</p>
<p>That is all for basic networking. General network parameters are set in
<em>group_vars/all/general_settings/network.yml</em> file, and nodes parameters are
defined in the node’s files.
Nodes <em>network_interfaces</em> are linked to logical networks.</p>
<p>Now, let’s have a look at the general configuration.</p>
</div>
<div class="section" id="review-general-configuration">
<h3><span class="section-number">6.2.5. </span>Review general configuration<a class="headerlink" href="#review-general-configuration" title="Permalink to this headline">¶</a></h3>
<p>General configuration is made in <em>group_vars/all/general_settings</em>.</p>
<div class="section" id="externals">
<h4><span class="section-number">6.2.5.1. </span>Externals<a class="headerlink" href="#externals" title="Permalink to this headline">¶</a></h4>
<p>File <em>group_vars/all/general_settings/external.yml</em> allows to configure external
resources. It should be self understandable.</p>
</div>
<div class="section" id="network">
<h4><span class="section-number">6.2.5.2. </span>Network<a class="headerlink" href="#network" title="Permalink to this headline">¶</a></h4>
<p>File <em>group_vars/all/general_settings/network.yml</em> allows to configure network
related parameters, and detail all networks of the cluster.</p>
</div>
<div class="section" id="repositories">
<h4><span class="section-number">6.2.5.3. </span>Repositories<a class="headerlink" href="#repositories" title="Permalink to this headline">¶</a></h4>
<p>File <em>group_vars/all/general_settings/repositories.yml</em> configure repositories to
use for all nodes (using groups and variable precedence, repositories can be
tuned for each group of nodes, or even each node).</p>
<p>Right now, only <em>os</em> and <em>bluebanquise</em> are set. This means two or three
(depending of the operating system) repositories will be added to nodes, and
they will bind to repository_ip in ice1-1.yml .</p>
<p>See the repositories_client role part of the documentation for advanced
configurations.</p>
<p>Note also that if you wish to define different repositories per equipment, you
can easily use variable precedence mechanism seen in the Ansible tutorial to
define repositories variable in each equipment group, or even for each node.</p>
</div>
<div class="section" id="nfs">
<h4><span class="section-number">6.2.5.4. </span>NFS<a class="headerlink" href="#nfs" title="Permalink to this headline">¶</a></h4>
<p>File <em>group_vars/all/general_settings/nfs.yml</em> allows to set NFS shared folders
inside the cluster. Comments in the file should be enough to understand this
file.</p>
</div>
<div class="section" id="general">
<h4><span class="section-number">6.2.5.5. </span>General<a class="headerlink" href="#general" title="Permalink to this headline">¶</a></h4>
<p>File <em>group_vars/all/general_settings/general.yml</em> configure few main parameters:</p>
<ul class="simple">
<li><p>Time zone (very important, should match the one of your current management server)</p></li>
</ul>
<p>Do not bother right now about the other parameters.</p>
<p>And that is all for general configuration. Finally, let’s check the equipment
default parameters.</p>
</div>
</div>
<div class="section" id="review-equipment-default-parameters">
<h3><span class="section-number">6.2.6. </span>Review equipment default parameters<a class="headerlink" href="#review-equipment-default-parameters" title="Permalink to this headline">¶</a></h3>
<p>Last part, and probably the most complex, are equipment profile groups default
parameters. As seen before, equipment profile groups are groups related to the
hardware, the models, of the nodes. Variables related to these groups will
define parameters related to hardware, but also operating system deployed on
them, etc.</p>
<p>Equipment variables are defined at a global level, then redefined if needed for
each equipment.</p>
<p>Remember Ansible precedence mechanism. All variables in <em>group_vars/all/</em> have
less priority, while variables in <em>group_vars/*</em> have a higher priority.</p>
<p>The idea here is the following: <em>group_vars/all/equipment_all/</em> folder contains
equipment default/global parameters for all nodes. Here authentication, and
equipment_profile. You have to tune these parameters to match your exact
“global” need, and then copy (if needed) part of these files into dedicated
group_vars folder for each equipment group, and tune them according to these
equipment specific parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can copy the whole equipment_profile.yml content from equipment_all to
equipment_X folders, <strong>or better</strong>, create a new file in equipment_X and only
set the parameters that are different from the global parameters.</p>
</div>
<p>For example, open file
<em>group_vars/all/equipment_all/equipment_profile.yml</em>,
and check access_control variable. It is set to enforcing:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">ep_access_control</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">enforcing</span>
</pre></div>
</div>
<p>Ok, but so all nodes will get this value. Let’s check computes nodes, that are
in equipment_typeC group. Let’s check compute1:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@<span class="o">]</span><span class="c1"># ansible-inventory --host compute1 --yaml | grep ep_access_control</span>
  ep_access_control: enforcing
<span class="o">[</span>root@<span class="o">]</span><span class="c1">#</span>
</pre></div>
</div>
<p>Lets say this is not good, and we want to disable access_control on computes.
We need to change that.</p>
<p>Open file <em>group_vars/equipment_typeC/equipment_profile.yml</em> and set
access_control to disabled.</p>
<p>Now check again:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>root@<span class="o">]</span><span class="c1"># ansible-inventory --host compute1 --yaml | grep ep_access_control</span>
  ep_access_control: disabled
<span class="o">[</span>root@<span class="o">]</span><span class="c1">#</span>
</pre></div>
</div>
<p>Same apply for all equipment_profile parameters. You define a global set of
parameters in equipment_all, which act as a global/default set, and then copy
(all or a part of them) and tune this set for each equipment group if needed.</p>
<img alt="_images/warning.svg" class="align-center" src="_images/warning.svg" /><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><strong>IMPORTANT</strong>: equipment_profile variables and authentication variables <strong>are
not standard</strong>. It is <strong>STRICTLY FORBIDDEN</strong> to tune them outside default
(group_vars/all/equipment_all/equipment_profile.yml) or an equipment group
(group_vars/equipment_*). For example, you cannot create a custom group and
define some equipment_profile parameters for this group. If you really need to
do that, add more equipment groups and tune this way. If you do not respect this
rule, unexpected behavior will happen during configuration deployment.</p>
</div>
<div class="section" id="equipment-profile-variables">
<h4><span class="section-number">6.2.6.1. </span>Equipment profile variables<a class="headerlink" href="#equipment-profile-variables" title="Permalink to this headline">¶</a></h4>
<p>Equipment profiles are variables dedicated to groups of nodes equipment. These
variables cover most of the hardware, operating system, PXE needs, etc. of the
related nodes.</p>
<img alt="_images/ep_hard.svg" class="align-center" src="_images/ep_hard.svg" /><p>Except for operating system and partitioning, default values should match for
a simple cluster with standard hardware.</p>
<p>Lets review them:</p>
<div class="section" id="pxe">
<h5><span class="section-number">6.2.6.1.1. </span>PXE<a class="headerlink" href="#pxe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ep_ipxe_driver</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>default</p></li>
<li><p>snp</p></li>
<li><p>snponly</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
See <a class="reference external" href="https://ipxe.org/appnote/buildtargets">https://ipxe.org/appnote/buildtargets</a>.
Most of servers should accept default driver, but snp or snponly can be required on some (with many NICs for example).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_ipxe_platform</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>pcbios</p></li>
<li><p>efi</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
This is the BIOS firmware type.
Should be detected automatically, but some roles need to force it.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_ipxe_embed</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>standard</p></li>
<li><p>dhcpretry</p></li>
<li><p>noshell</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
standard is ok for most cases. dhcpretry is to be used on networks where
link on switch may take some time to go up. In dhcpretry mode, the iPXE rom
will indefinitely try to get an ip from the dhcp.
noshell is similar to standard, but without shell in case of issues. This
allows “exit” EFI boot, for specific devices (like Nvidia DGX).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_preserve_efi_first_boot_device</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>true</p></li>
<li><p>false</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
Try to force grub to restore EFI boot order during OS deployment. Allows to
keep PXE first for example.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="kernel-settings">
<h5><span class="section-number">6.2.6.1.2. </span>Kernel settings<a class="headerlink" href="#kernel-settings" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ep_console</strong></dt><dd><ul>
<li><p>Notes:
Custom value: the server console to be used. For example: console=tty0 console=ttyS1,115200n8</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_kernel_parameters</strong></dt><dd><ul>
<li><p>Notes:
Custom value: additional kernel parameters to be added on kernel line.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_sysctl</strong></dt><dd><ul>
<li><p>Notes:
Custom value: additional sysctl kernel parameters.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="security">
<h5><span class="section-number">6.2.6.1.3. </span>Security<a class="headerlink" href="#security" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ep_access_control</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>enforcing</p></li>
<li><p>permissive</p></li>
<li><p>disabled</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
Activate or not the access control (SELinux, etc.).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_firewall</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>true</p></li>
<li><p>false</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
Activate or not the firewall (firewalld, etc.).</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="operating-system-setup">
<h5><span class="section-number">6.2.6.1.4. </span>Operating system setup<a class="headerlink" href="#operating-system-setup" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ep_partitioning</strong></dt><dd><ul>
<li><p>Notes:
Custom value: contains the partitioning multiple lines to be used. It is
expected here native distribution syntax. For example, for RHEL/CentOS, use
plain kickstart partitioning syntax (allows full custom partitioning).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_autoinstall_pre_script</strong></dt><dd><ul>
<li><p>Notes:
To add a multiple lines %pre script in the auto deployment file (kickstart,
autoyast, preseed, etc.)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_autoinstall_post_script</strong></dt><dd><ul>
<li><p>Notes:
To add a multiple lines %post script in the auto deployment file (kickstart,
autoyast, preseed, etc.)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_operating_system</strong></dt><dd><ul>
<li><dl class="simple">
<dt><strong>distribution</strong></dt><dd><ul>
<li><p>Notes:
Custom value: set the distribution to be used here. This will be
directly related to the repository used. Standard values are: centos,
redhat, debian, ubuntu, opensuse, etc.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>distribution_major_version</strong></dt><dd><ul>
<li><p>Notes:
Custom value: set the distribution major version number or string.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>distribution_version</strong></dt><dd><ul>
<li><p>Notes:
Custom and optional value: set the distribution minor/custom version to
be used. This will force repositories and PXE to use a minor version
instead of relying on a major.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>repositories_environment</strong></dt><dd><ul>
<li><p>Notes:
Custom and optional value: set a production environment, to prepend all
paths to be used (see repositories_client role documentation). For
example: production, staging, test, etc.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_configuration</strong></dt><dd><ul>
<li><dl class="simple">
<dt>keyboard_layout**</dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>us</p></li>
<li><p>fr</p></li>
<li><p>etc.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
Set the keyboard layout.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>system_language**</dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>en_US.UTF-8</p></li>
<li><p>etc.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
Set the system locals. It is strongly recommended to keep en_US.UTF-8.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="hardware">
<h5><span class="section-number">6.2.6.1.5. </span>Hardware<a class="headerlink" href="#hardware" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ep_equipment_type</strong></dt><dd><ul>
<li><dl class="simple">
<dt>Possible values:</dt><dd><ul>
<li><p>server</p></li>
<li><p>any other custom values but not “server”</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Notes:
If server, then PXE files will be generated by the pxe_stack role. If not,
then value can be custom (and no PXE files will be generated).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>ep_hardware</strong></dt><dd><ul>
<li><p>Notes:
Multiple fields to define system architecture. Some addon roles (like slurm)
may rely on these values.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="board-credentials-bmc-controller-other">
<h5><span class="section-number">6.2.6.1.6. </span>Board credentials (BMC, controller, other)<a class="headerlink" href="#board-credentials-bmc-controller-other" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ep_equipment_authentication</strong></dt><dd><ul>
<li><dl class="simple">
<dt><strong>user</strong></dt><dd><ul>
<li><p>Notes:
Custom value: set the BMC, storage bay controller, switch, etc. user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>password</strong></dt><dd><ul>
<li><p>Notes:
Custom value: set the BMC, storage bay controller, switch, etc. password.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
</div>
<div class="section" id="authentication">
<h4><span class="section-number">6.2.6.2. </span>Authentication<a class="headerlink" href="#authentication" title="Permalink to this headline">¶</a></h4>
<p>Authentication file allows to define default root password for all nodes, and
default public ssh keys lists.</p>
<p>To generate an sha512 password, use the following command (python &gt;3.3):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>python -c &#39;import crypt,getpass; print(crypt.crypt(getpass.getpass(), crypt.mksalt(crypt.METHOD_SHA512)))&#39;
</pre></div>
</div>
<p>We need to ensure our management1 node ssh public key is set here.</p>
<p>Get the content of <em>/root/.ssh/id_ed25519.pub</em> and add it in this file. At the
same time, <strong>remove the ssh key provided here as example</strong>.</p>
<p>It is possible to do it automatically using the following command:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># Copy public key of the mgmt to the inventory
/usr/bin/sed -i -e &quot;s#- ssh-rsa.*#- $(cat /root/.ssh/id_ed25519.pub)#&quot; \
  /etc/bluebanquise/inventory/group_vars/all/equipment_all/authentication.yml
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you update the managements ssh keys, do not forget to update this file.</p>
</div>
<hr class="docutils" />
<p>Once done, configuration is ready.</p>
<p>Remember that a data model is available in <em>resources/data_model.md</em> on the
BlueBanquise github.</p>
<p>It is time to deploy configuration on management1.</p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="deploy_bluebanquise.html" class="btn btn-neutral float-right" title="7. [Core] - Deploy BlueBanquise" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="bootstrap.html" class="btn btn-neutral float-left" title="5. [Core] - Bootstrap base system" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2019, Benoît Leveugle, Johnny Keats.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>