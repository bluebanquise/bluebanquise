

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>8. [Core] - Manage multiple icebergs &mdash; BlueBanquise Documentation 1.5.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. [Core] - Diskless" href="diskless.html" />
    <link rel="prev" title="7. [Core] - Deploy BlueBanquise" href="deploy_bluebanquise.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> BlueBanquise Documentation
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="vocabulary.html">2. Vocabulary</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_sysadmin.html">3. [Training] - Cluster SysAdmin</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_ansible.html">4. [Training] - Ansible</a></li>
<li class="toctree-l1"><a class="reference internal" href="bootstrap.html">5. [Core] - Bootstrap base system</a></li>
<li class="toctree-l1"><a class="reference internal" href="configure_bluebanquise.html">6. [Core] - Configure BlueBanquise</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_bluebanquise.html">7. [Core] - Deploy BlueBanquise</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8. [Core] - Manage multiple icebergs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#iceberg-elements">8.1. Iceberg elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configuring-top-iceberg">8.2. Configuring top iceberg</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#understanding-mechanism">8.2.1. Understanding mechanism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enabling-iceberg-mechanism">8.2.2. Enabling iceberg mechanism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-iceberg-1">8.2.3. Create iceberg 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-iceberg-2">8.2.4. Create iceberg 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-sub-management-configuration">8.2.5. Deploy sub management configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#using-nfs">8.2.5.1. Using NFS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-syncthings">8.2.5.2. Using SyncThings</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deploy-configuration">8.2.5.3. Deploy configuration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#interconnect-and-job-scheduler-hpc-only">8.2.6. Interconnect and job scheduler (HPC only)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="diskless.html">9. [Core] - Diskless</a></li>
<li class="toctree-l1"><a class="reference internal" href="high_availability.html">10. [Community] - High Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitoring.html">11. [Community] - Monitoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="containers.html">12. Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="stories.html">13. Stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="roles.html">14. Roles list</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">15. References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BlueBanquise Documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><span class="section-number">8. </span>[Core] - Manage multiple icebergs</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/multiple_icebergs.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="core-manage-multiple-icebergs">
<h1><span class="section-number">8. </span>[Core] - Manage multiple icebergs<a class="headerlink" href="#core-manage-multiple-icebergs" title="Permalink to this headline">¶</a></h1>
<p>Now that the simple configuration has been tested and done, it is possible
to extend the cluster, by activating the multiple icebergs mechanism.</p>
<p>Icebergs mechanism allows to split cluster into parts, in order to:</p>
<ul class="simple">
<li><p>Distribute load over multiple managements nodes.</p></li>
<li><p>Isolate part of the cluster from the others, while keeping if needed an unified interconnect network.</p></li>
</ul>
<p>It is important to understand what is an iceberg in BlueBanquise.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>An iceberg is also often called an <em>island</em> in High Performance Computing
domain.</p>
</div>
<div class="section" id="iceberg-elements">
<h2><span class="section-number">8.1. </span>Iceberg elements<a class="headerlink" href="#iceberg-elements" title="Permalink to this headline">¶</a></h2>
<p>Each iceberg is composed of:</p>
<ul class="simple">
<li><p>A set of dedicated management nodes (can be bare metal servers, VMs, containers, etc.).</p></li>
<li><p>Some hosts part of this iceberg, and managed by the iceberg management nodes.</p></li>
<li><p>Iceberg isolated management networks, called <strong>iceX-Y</strong> by default, with X the iceberg number (starting from 1).</p></li>
<li><p>An Ansible group, with all management nodes and hosts part of the iceberg.</p></li>
</ul>
<p>Icebergs are connected together using a simple hierarchical pattern:
an iceberg can be a <strong>top</strong>, meaning it is the top in the hierarchy,
or be a <strong>standard</strong> iceberg, meaning it will refer to a master iceberg
(which can be a <strong>top</strong> iceberg, or another <strong>standard</strong> iceberg if more than 2
levels).</p>
<p>The following schema summarize an example target architecture:</p>
<img alt="_images/multiple_icebergs_1.svg" src="_images/multiple_icebergs_1.svg" /><p>Few notes about this schema:</p>
<ul class="simple">
<li><p>Icebergs managements can be connected to any administration networks.</p></li>
<li><p>Managements of a <em>standard iceberg</em> are expected to be connected <strong>to both administration network</strong>,
i.e. on one of their internal iceberg administration network, but also on one of the administration network of their master iceberg
(so here, one above, and one bellow).</p></li>
<li><p>Services will work as a chain. For example, time will come from the top iceberg (or an external source) and each time server will take as source the time server of its master iceberg.</p></li>
</ul>
<p>And the following schema summarize scope of each iceberg for the following
examples:</p>
<img alt="_images/multiple_icebergs_1bis.svg" src="_images/multiple_icebergs_1bis.svg" /><p>Note that this architecture is flexible, and can be adapted to create isolated
icebergs (i.e. having multiple fully isolated clusters in the same BlueBanquise
configuration).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note also that using iceberg related groups, it is possible to define variables
dedicated to each iceberg (for example, define a different time zone, a
different domain name, etc.).
However, and this is <strong>important</strong>, variables defined in <em>group_vars/equipment_X</em>
(prefixed by <strong>ep_</strong> and <strong>authentication_</strong>) should never be used in icebergs
groups, i.e. <em>group_vars/icebergX</em>, as this is incompatible with the stack
logic: some roles expect all the members of equipment_profile groups to have
the same values for each <strong>ep_</strong> and <strong>authentication_</strong> parameters.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a physician, I start counting at 1 when speaking of physical things, and so
icebergs are numbered at 1 by default. However, nothing prevents using 0 as a
start point when activating icebergs mechanism.</p>
</div>
<p>We are going to split the target cluster of the main documentation into
different icebergs.</p>
<p>Iceberg1 will be the top iceberg, and icebergs 2, 3 and 4 will be standard
icebergs, with iceberg1 as master iceberg.</p>
</div>
<div class="section" id="configuring-top-iceberg">
<h2><span class="section-number">8.2. </span>Configuring top iceberg<a class="headerlink" href="#configuring-top-iceberg" title="Permalink to this headline">¶</a></h2>
<div class="section" id="understanding-mechanism">
<h3><span class="section-number">8.2.1. </span>Understanding mechanism<a class="headerlink" href="#understanding-mechanism" title="Permalink to this headline">¶</a></h3>
<p>By default, iceberg mechanism is deactivated, and so all hosts are considered
member of iceberg1.</p>
<p>This automation is achieved by j2 variable j2_current_iceberg, in file
internal/group_vars/all/j2_variables/icebergs.yml:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>j2_current_iceberg: &quot;{% if not icebergs_system %}{{ iceberg_naming+&#39;1&#39; }}{% else %}{{ group_names | select(&#39;match&#39;,&#39;^&#39;+iceberg_naming+&#39;[0-9]+&#39;) | list | unique | sort | first | join }}{% endif %}&quot;
</pre></div>
</div>
<p>So to resume this code, assuming we are working on host <em>c001</em> which is part of <em>iceberg2</em> group:</p>
<img alt="_images/multiple_icebergs_j2.svg" src="_images/multiple_icebergs_j2.svg" /><ul class="simple">
<li><dl class="simple">
<dt><strong>If</strong> <em>icebergs_system</em> is set to <em>false</em></dt><dd><ul>
<li><p>-&gt; <strong>Then</strong> iceberg is <em>iceberg_naming+’1’ = iceberg1</em>.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>If</strong> <em>icebergs_system</em> is set to <em>true</em></dt><dd><ul>
<li><p>-&gt; <strong>Then</strong> j2_current_iceberg will check groups the current hosts is member of (<em>group_names</em>), and look for a group with pattern <em>iceberg_naming+’[0-9]+’</em>, and use it to determine current iceberg.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Then, other values will be deduced from this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>j2_current_iceberg_number: &quot;{{ j2_current_iceberg | replace(iceberg_naming,&#39; &#39;) | trim }}&quot;
j2_current_iceberg_network: &quot;{{ management_networks_naming + (j2_current_iceberg_number|string) }}&quot;
</pre></div>
</div>
<ul class="simple">
<li><p>j2_current_iceberg_number is simply the j2_current_iceberg without the “iceberg” string, so the iceberg number, here “2”.</p></li>
<li><p>j2_current_iceberg_network is the addition of the default network naming and the iceberg number, so here “ice2”.</p></li>
</ul>
<p>Note also that 2 variables are here to simplify developments of templates:</p>
<ul class="simple">
<li><p>j2_icebergs_groups_list: “{{ groups | select(‘match’,’^’+iceberg_naming+’[0-9]+’) | list }}”</p></li>
<li><p>j2_number_of_icebergs: “{{ groups | select(‘match’,’^’+iceberg_naming+’[0-9]+’) | list | length }}”</p></li>
</ul>
<p>Variables names are self explaining these variables.</p>
</div>
<div class="section" id="enabling-iceberg-mechanism">
<h3><span class="section-number">8.2.2. </span>Enabling iceberg mechanism<a class="headerlink" href="#enabling-iceberg-mechanism" title="Permalink to this headline">¶</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Do not play any role from now, until hosts are in their iceberg group.</p>
</div>
<p>To activate icebergs mechanism, open file
<em>group_vars/all/general_settings/general.yml</em>, and set <em>icebergs_system</em> to
<strong>true</strong>.</p>
</div>
<div class="section" id="create-iceberg-1">
<h3><span class="section-number">8.2.3. </span>Create iceberg 1<a class="headerlink" href="#create-iceberg-1" title="Permalink to this headline">¶</a></h3>
<p>We now need to create the iceberg1 group, define its variables, and add hosts
into it.</p>
<p>Create dedicated folder if absent:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir /etc/bluebanquise/inventory/cluster/icebergs/
</pre></div>
</div>
<p>Then create file <em>inventory/cluster/icebergs/iceberg1</em>,
and add the following content:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[iceberg1:vars]
iceberg_master = top
iceberg_level = 1

[iceberg1]
</pre></div>
</div>
<p>This will create an Ansible group called iceberg1, with 2 associated variables.</p>
<ul class="simple">
<li><p><strong>iceberg_master</strong> defines if the iceberg is a <strong>top</strong>, or a <strong>standard</strong> iceberg linked to a master.</p></li>
<li><p><strong>iceberg_level</strong> defines the level of this iceberg in the services chain. This is for example used to calculate stratum value of time servers, etc.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>iceberg_level could be automatically calculated. However, having it as a
variable allows the system administrator to tune it to desired ways.</p>
</div>
<p>Let’s check current groups status:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[root@mngt1 ~]# ansible-inventory --graph
@all:
...
  |--@iceberg1:
  |--@ungrouped:
[root@mngt1 ~]#
</pre></div>
</div>
<p>iceberg1 group has been created, and is empty. Now add management(s) and nodes
of the current iceberg into it.</p>
<p>To do so, edit again file <em>inventory/cluster/icebergs/iceberg1</em> and under
<em>[iceberg1]</em> simply add hosts:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[iceberg1:vars]
iceberg_master = top
iceberg_level = 1

[iceberg1]
management1
login[1:2]
storage[1:6]
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As you can see, it is possible to add ranges of nodes, like in this example
with login[1:2]. This is a different syntax than ClusterShell’s nodeset or
SchedMD’s Slurm.</p>
</div>
<p>Check groups again:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[root@mngt1 ~]# ansible-inventory --graph
@all:
...
  |--@iceberg1:
  |  |--management1
  |  |--login1
  |  |--login2
  |  |--storage1
  |  |--storage2
  |  |--storage3
  |  |--storage4
  |  |--storage5
  |  |--storage6
  |--@ungrouped:
[root@mngt1 ~]#
</pre></div>
</div>
<p>And push this new configuration using your dedicated playbook for each already
deployed hosts.
It is possible to see what is going to be modified using <em>–diff –check</em> at
ansible-playbook invocation.</p>
<p>There should not be major modifications in configuration for hosts of iceberg1.</p>
</div>
<div class="section" id="create-iceberg-2">
<h3><span class="section-number">8.2.4. </span>Create iceberg 2<a class="headerlink" href="#create-iceberg-2" title="Permalink to this headline">¶</a></h3>
<p>Create now a second iceberg, with iceberg1 as master.</p>
<p>Create file <em>inventory/cluster/icebergs/iceberg2</em>, with the following content:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[iceberg2:vars]
iceberg_master = iceberg1
iceberg_level = 2

[iceberg2]
</pre></div>
</div>
<p>This new iceberg is not a top iceberg, and so refer to its master, here
iceberg1.</p>
<p>Configure a new management, called mngt2, that will be in charge of iceberg2.
According to icebergs definition, mngt2 must be connected to both ice1-1 network
and ice2-1 network.</p>
<p>For convenience, we create a dedicated folder in cluster directory to store all
nodes related to each iceberg. We also move all current nodes into iceberg1
directory.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mkdir -p /etc/bluebanquise/inventory/cluster/nodes/iceberg1/
mkdir -p /etc/bluebanquise/inventory/cluster/nodes/iceberg2/
mv /etc/bluebanquise/inventory/cluster/*.yml /etc/bluebanquise/inventory/cluster/nodes/iceberg1/
</pre></div>
</div>
<p>A warning may be displayed during playbook execution for now, because
<em>nodes/iceberg2/</em> is still empty.</p>
<p>Now create mngt2 file dedicated file
<em>inventory/cluster/nodes/iceberg2/management.yml</em> with the following content:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">mg_managements</span><span class="p">:</span>
  <span class="nt">children</span><span class="p">:</span>
    <span class="nt">equipment_typeM</span><span class="p">:</span>
      <span class="nt">hosts</span><span class="p">:</span>
        <span class="nt">mngt2</span><span class="p">:</span>
          <span class="nt">bmc</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bmngt2</span>
            <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.100.2</span>
            <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:0d:41:97</span>
            <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
          <span class="nt">network_interfaces</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">interface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">enp0s8</span>
              <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.12.0.1</span>
              <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:de:42:23</span>
              <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice2-1</span>
            <span class="p p-Indicator">-</span> <span class="nt">interface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">enp0s3</span>
              <span class="nt">ip4</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.10.0.2</span>
              <span class="nt">mac</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">08:00:27:de:41:21</span>
              <span class="nt">network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
</pre></div>
</div>
<p>This host is connected to both icebergs, and will be pushed from ice1-1 and act
as a pusher (management) on ice2-1.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Two important things, related to network.
First, BMC is connected to ice1-1, as mngt1 is in charge of deploying mngt2.
Secondly, here, network_interface connected to network ice2-1 <strong>MUST BE THE
FIRST</strong> in the list. This is key, as you need nodes to reach mngt2 to its main
iceberg interface. Only mngt1 should need access to ice1-1 interface of mngt2,
and the <em>ssh_master</em> role will ensure that Ansible from mngt1 use this one.</p>
</div>
<p>Add mngt2 to iceberg2, by editing <em>inventory/cluster/icebergs/iceberg2</em> and
adding mngt2 under [iceberg2]:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[iceberg2:vars]
iceberg_master = iceberg1
iceberg_level = 2

[iceberg2]
mngt2
</pre></div>
</div>
<p>Play again playbooks on mngt1, so mngt2 is added into dhcp, pxe, dns, hosts,
etc. configuration files.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Even if mngt2 is not part of iceberg1, it has been added to configuration
files on mngt1, like any other nodes of iceberg1. All nodes part of group
<em>mg_managements</em> and part of a sub iceberg group are automatically added, as
they also need to be deployed from this iceberg, like any other nodes.</p>
</div>
<p>Once done, use standard procedure to deploy OS on mngt2 from mngt1 (<em>bootset</em>,
etc).</p>
<p>Now, few steps has to be followed in a specific order to deploy
configuration on mngt2.</p>
</div>
<div class="section" id="deploy-sub-management-configuration">
<h3><span class="section-number">8.2.5. </span>Deploy sub management configuration<a class="headerlink" href="#deploy-sub-management-configuration" title="Permalink to this headline">¶</a></h3>
<p>Sub managements (here mngt2) need to have locally access to the repositories and
BlueBanquise inventory that are currently stored on top managements
(here mngt1).</p>
<p>There are multiple strategy to achieve that. Two are proposed here:</p>
<ol class="arabic simple">
<li><p>using an NFS share (if good network bandwidth and small storage)</p></li>
<li><p>using SyncThings tool (good if you have enough storage)</p></li>
</ol>
<div class="section" id="using-nfs">
<h4><span class="section-number">8.2.5.1. </span>Using NFS<a class="headerlink" href="#using-nfs" title="Permalink to this headline">¶</a></h4>
<p>We will ensure that mngt2 mount over nfs the repositories and the BlueBanquise
inventory from mngt1.
This to be able to install packages, but also act as a repository server for
its iceberg, and be able to deploy the configuration on its iceberg nodes.</p>
<p>We need to ensure mngt2 is part of a group that will mount the repositories and
bluebanquise, in nfs.yml. By default, this group is called
<em>secondary_managements</em>.</p>
<p>Create file <em>inventory/cluster/groups/secondary_managements</em> with the following
content:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[secondary_managements]
mngt2
</pre></div>
</div>
<p>Then ensure in file <em>inventory/group_vars/all/general_settings/nfs.yml</em> you have
at least these two exports:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">nfs</span><span class="p">:</span>

  <span class="l l-Scalar l-Scalar-Plain">...</span>

  <span class="l l-Scalar l-Scalar-Plain">bluebanquise</span><span class="p p-Indicator">:</span>
    <span class="nt">mount</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/bluebanquise</span>
    <span class="nt">export</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/bluebanquise</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">mngt1</span>
    <span class="nt">clients_groups</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">secondary_managements</span>
    <span class="nt">take_over_network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
    <span class="nt">export_arguments</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ro,no_root_squash,sync</span>
    <span class="nt">mount_arguments</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ro,intr,nfsvers=4.2,bg</span>

  <span class="nt">repositories</span><span class="p">:</span>
    <span class="nt">mount</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/var/www/html/repositories</span>
    <span class="nt">export</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/var/www/html/repositories</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">mngt1</span>
    <span class="nt">clients_groups</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">secondary_managements</span>
    <span class="nt">take_over_network</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ice1-1</span>
    <span class="nt">export_arguments</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ro,no_root_squash,sync</span>
    <span class="nt">mount_arguments</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ro,intr,rsize=32768,wsize=32768,nfsvers=4.2,bg</span>
</pre></div>
</div>
<p>So mngt1 will export both folders, and members of secondary_managements (so
mngt2) will mount it.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All is set to read only here (ro). It is up to you to switch to read write if
needed.</p>
</div>
<p>If you just added these new nfs exports, play the role nfs_server on mngt1 and
check that mngt1 now export these foldes, using <em>showmount -e mngt1</em> command.</p>
<p>Next, we will need a playbook for mngt2. Copy current mngt1 dedicated playbook:</p>
<dl class="simple">
<dt>..note ::</dt><dd><p>We assume here mngt1.yml playbook exist. You may have used another name for it:
managements.yml, management1.yml, etc. Please adapt these instructions to
your own environment.</p>
</dd>
</dl>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>cp /etc/bluebanquise/playbooks/mngt1.yml /etc/bluebanquise/playbooks/mngt2.yml
</pre></div>
</div>
<p>And change target host inside to match mngt2.</p>
<p>From now, few steps need to be done in a very strict order. We are going to
force mngt2 to be part of iceberg1 for few commands, in order to be able to
bootstrap it. To do so, we will execute the mngt2.yml playbook, with an extra
variable, that will force <em>j2_current_iceberg</em> to be <strong>iceberg1</strong>.</p>
<img alt="_images/multiple_icebergs_3.svg" src="_images/multiple_icebergs_3.svg" /><p>We need first mngt2 to be able to install packages, and so to use mngt1 as
repositories server.</p>
<p>Deploy repositories_client role, by forcing mngt2 to be temporary part of
iceberg1:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mngt1# ansible-playbook /etc/bluebanquise/playbooks/mngt2.yml -t repositories_client --extra-vars j2_current_iceberg=iceberg1
</pre></div>
</div>
<p>Packages can now be downloaded from mngt1 to mngt2 and installed on mngt2.</p>
<img alt="_images/multiple_icebergs_4.svg" src="_images/multiple_icebergs_4.svg" /><p>Then deploy nfs_client role, and repositories_server role, so that mngt2 can get
repositories locally and distribute them on iceberg2:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mngt1# ansible-playbook /etc/bluebanquise/playbooks/mngt2.yml -t nfs_client,repositories_server --extra-vars j2_current_iceberg=iceberg1
</pre></div>
</div>
<p><em>/var/www/html/repositories</em> and <em>/etc/bluebanquise</em> from mngt1 are now mounted
on mngt2, and httpd server is running on mngt2.</p>
<img alt="_images/multiple_icebergs_5.svg" src="_images/multiple_icebergs_5.svg" /></div>
<div class="section" id="using-syncthings">
<h4><span class="section-number">8.2.5.2. </span>Using SyncThings<a class="headerlink" href="#using-syncthings" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="deploy-configuration">
<h4><span class="section-number">8.2.5.3. </span>Deploy configuration<a class="headerlink" href="#deploy-configuration" title="Permalink to this headline">¶</a></h4>
<p>Now, mngt2 can be autonomous and do not need to be part of iceberg1.
Deploy the whole configuration on it:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mngt1# ansible-playbook /etc/bluebanquise/playbooks/mngt2.yml
</pre></div>
</div>
<p>From now, mngt2 act as iceberg2 management, and can provide packages to its
pool of client nodes.</p>
<img alt="_images/multiple_icebergs_6.svg" src="_images/multiple_icebergs_6.svg" /><p>And proceed as usual to add more hosts into iceberg2 and deploy them,
this time from mngt2.</p>
<p>Redo this same process for each additional island.</p>
</div>
</div>
<div class="section" id="interconnect-and-job-scheduler-hpc-only">
<h3><span class="section-number">8.2.6. </span>Interconnect and job scheduler (HPC only)<a class="headerlink" href="#interconnect-and-job-scheduler-hpc-only" title="Permalink to this headline">¶</a></h3>
<p>Now that your icebergs are up and running comes the question of the interconnect
(if exist) and the job scheduler (by default Slurm). Same question can be made
for the storage: you may need all nodes to reach a network FS (Lustre, BeeGFS,
etc.).</p>
<img alt="_images/multiple_icebergs_7.svg" src="_images/multiple_icebergs_7.svg" /><p>For storage, it should be straightforward: once the storage is online and
reachable over the interconnect, all nodes can mount it.</p>
<p>The Slurm setup is a little bit more complex. You will need a unified network to
allow your nodes to be able to reach the same Slurm controller, mostly running
on the mngt1 server.</p>
<p>But you will also need to ensure direct hostnames resolution of all computes
nodes is done on the interconnect, and not on the internet. Why? Simply because
when parallel computations take places, Slurm will provide to the instance nodes
hostnames as target, and so if nodes need to reach each other through ethernet,
nodes from one iceberg will not be able to reach nodes from other icebergs, and
so parallel computations will not initialize.</p>
<p>Example: user job is asking for 100 nodes, the whole cluster is free, and each
iceberg contains 80 nodes. Slurm will allocate 80 nodes from iceberg1, lets say
c[001-080] and 20 nodes from iceberg2, c[081-100]. The final mpirun command
will receive as hosts target c[001-100]. c001 will be able to communicate with
c002, but not with c081, as iceberg ethernet networks are isolated. But if c081
resolves to c081 over the interconnect network, then since this network is
unified, c001 will be able to reach c081 and initialize MPI run.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is possible to set routing between icebergs over ethernet, but this is not
in the scope of this documentation.</p>
</div>
<p>To achieve direct computes hosts resolution over interconnect, ensure the
interconnect network interface is first in the network_interface list of each
compute node, which is the preferred network.</p>
<p>For example:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>hosts:
  c001:
    bmc:
      name: bc001
      ip4: 10.2.103.1
      mac: 08:00:27:0d:f8:a5
      network: ice2-1
    network_interfaces:
      - interface: enp0s3
        ip4: 10.2.3.1
        mac: 08:00:27:0d:f8:a6
        network: ice2-1
      - interface: ib0
        ip4: 10.20.3.1
        network: interconnect-1
</pre></div>
</div>
<p>Becomes:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>hosts:
  c001:
    bmc:
      name: bc001
      ip4: 10.2.103.1
      mac: 08:00:27:0d:f8:a5
      network: ice2-1
    network_interfaces:
      - interface: ib0
        ip4: 10.20.3.1
        network: interconnect-1
      - interface: enp0s3
        ip4: 10.2.3.1
        mac: 08:00:27:0d:f8:a6
        network: ice2-1
</pre></div>
</div>
<p>Using this, all nodes will now be able to communicate directly over the
interconnect.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Having interconnect here as direct resolution is not an issue to deploy
configuration with Ansible. By default, the ss_master role force the ssh from
a management to targets to be done on the first management network in the
target network_interfaces list. In this example, a ping c001 will ping the
ib0 interface connected to the ib0 network, so 10.20.3.1, but an ssh c001 will
connect to c001 through interface enp0s3 connected to the ice2-1 network, so
10.2.3.1.</p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="diskless.html" class="btn btn-neutral float-right" title="9. [Core] - Diskless" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="deploy_bluebanquise.html" class="btn btn-neutral float-left" title="7. [Core] - Deploy BlueBanquise" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2019, Benoît Leveugle, Johnny Keats.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>